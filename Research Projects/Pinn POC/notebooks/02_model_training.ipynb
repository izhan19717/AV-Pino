{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AV-PINO Model Training\n",
    "\n",
    "This notebook demonstrates the complete training pipeline for the AV-PINO motor fault diagnosis system, including:\n",
    "\n",
    "- Physics-informed loss functions\n",
    "- Multi-physics coupling\n",
    "- Uncertainty quantification training\n",
    "- Training monitoring and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Import AV-PINO components\n",
    "from config.experiment_config import ExperimentManager\n",
    "from data.cwru_loader import CWRUDataLoader\n",
    "from data.preprocessor import DataPreprocessor\n",
    "from training.training_engine import TrainingEngine\n",
    "from training.physics_informed_loss import PhysicsInformedLoss\n",
    "from training.advanced_loss_functions import AdvancedLossManager\n",
    "from validation.benchmarking_suite import BenchmarkingSuite\n",
    "from visualization.visualization_manager import VisualizationManager\n",
    "\n",
    "print(\"Training components imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Experiment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment configuration\n",
    "config_manager = ExperimentManager()\n",
    "config = config_manager.create_default_config()\n",
    "\n",
    "# Training-specific configuration\n",
    "config.training.update({\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"scheduler\": \"cosine\",\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"gradient_clip\": 1.0\n",
    "})\n",
    "\n",
    "# Physics loss configuration\n",
    "config.physics[\"loss_weights\"] = {\n",
    "    \"data\": 1.0,\n",
    "    \"physics\": 0.1,\n",
    "    \"consistency\": 0.05,\n",
    "    \"variational\": 0.01\n",
    "}\n",
    "\n",
    "# Setup reproducibility\n",
    "final_config = config_manager.setup_experiment()\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {final_config.training['epochs']}\")\n",
    "print(f\"  Batch size: {final_config.training['batch_size']}\")\n",
    "print(f\"  Learning rate: {final_config.training['learning_rate']}\")\n",
    "print(f\"  Physics loss weights: {final_config.physics['loss_weights']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data components\n",
    "data_loader = CWRUDataLoader()\n",
    "preprocessor = DataPreprocessor(final_config)\n",
    "\n",
    "# Load and preprocess data\n",
    "try:\n",
    "    # Load CWRU dataset\n",
    "    train_data, val_data, test_data = data_loader.load_dataset(\n",
    "        data_path=\"../data/cwru\",\n",
    "        download=True,\n",
    "        train_split=0.7,\n",
    "        val_split=0.15,\n",
    "        test_split=0.15\n",
    "    )\n",
    "    \n",
    "    print(f\"Dataset loaded successfully:\")\n",
    "    print(f\"  Training samples: {len(train_data)}\")\n",
    "    print(f\"  Validation samples: {len(val_data)}\")\n",
    "    print(f\"  Test samples: {len(test_data)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Using synthetic data for demonstration: {e}\")\n",
    "    \n",
    "    # Create synthetic dataset\n",
    "    train_data = data_loader.create_synthetic_dataset(1000)\n",
    "    val_data = data_loader.create_synthetic_dataset(200)\n",
    "    test_data = data_loader.create_synthetic_dataset(200)\n",
    "\n",
    "# Preprocess data\n",
    "train_processed = preprocessor.preprocess_dataset(train_data)\n",
    "val_processed = preprocessor.preprocess_dataset(val_data)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_processed, \n",
    "    batch_size=final_config.training[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_processed,\n",
    "    batch_size=final_config.training[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model and Loss Function Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize training engine\n",
    "training_engine = TrainingEngine(final_config)\n",
    "\n",
    "# Get model architecture\n",
    "model = training_engine.create_model()\n",
    "print(f\"Model created: {model.__class__.__name__}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Initialize physics-informed loss\n",
    "physics_loss = PhysicsInformedLoss(final_config)\n",
    "advanced_loss = AdvancedLossManager(final_config)\n",
    "\n",
    "print(f\"Loss functions initialized:\")\n",
    "print(f\"  Physics constraints: {physics_loss.constraint_types}\")\n",
    "print(f\"  Loss weights: {physics_loss.loss_weights}\")\n",
    "\n",
    "# Setup optimizer and scheduler\n",
    "optimizer = training_engine.create_optimizer(model)\n",
    "scheduler = training_engine.create_scheduler(optimizer)\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Scheduler: {scheduler.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop with Physics Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training monitoring\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'data_loss': [],\n",
    "    'physics_loss': [],\n",
    "    'consistency_loss': [],\n",
    "    'accuracy': [],\n",
    "    'physics_violations': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(final_config.training[\"epochs\"]):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_metrics = training_engine.train_epoch(\n",
    "        model, train_loader, optimizer, physics_loss, epoch\n",
    "    )\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_metrics = training_engine.validate_epoch(\n",
    "        model, val_loader, physics_loss, epoch\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Record metrics\n",
    "    training_history['train_loss'].append(train_metrics['total_loss'])\n",
    "    training_history['val_loss'].append(val_metrics['total_loss'])\n",
    "    training_history['data_loss'].append(train_metrics['data_loss'])\n",
    "    training_history['physics_loss'].append(train_metrics['physics_loss'])\n",
    "    training_history['consistency_loss'].append(train_metrics['consistency_loss'])\n",
    "    training_history['accuracy'].append(val_metrics['accuracy'])\n",
    "    training_history['physics_violations'].append(train_metrics['physics_violations'])\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{final_config.training['epochs']}:\")\n",
    "        print(f\"  Train Loss: {train_metrics['total_loss']:.4f}\")\n",
    "        print(f\"  Val Loss: {val_metrics['total_loss']:.4f}\")\n",
    "        print(f\"  Val Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "        print(f\"  Physics Violations: {train_metrics['physics_violations']:.6f}\")\n",
    "        print(f\"  Learning Rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\nTraining completed in {training_time:.2f} seconds\")\n",
    "print(f\"Final validation accuracy: {training_history['accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Loss curves\n",
    "axes[0, 0].plot(training_history['train_loss'], label='Train Loss')\n",
    "axes[0, 0].plot(training_history['val_loss'], label='Val Loss')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# Component losses\n",
    "axes[0, 1].plot(training_history['data_loss'], label='Data Loss')\n",
    "axes[0, 1].plot(training_history['physics_loss'], label='Physics Loss')\n",
    "axes[0, 1].plot(training_history['consistency_loss'], label='Consistency Loss')\n",
    "axes[0, 1].set_title('Loss Components')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Loss')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "axes[0, 1].set_yscale('log')\n",
    "\n",
    "# Accuracy\n",
    "axes[0, 2].plot(training_history['accuracy'])\n",
    "axes[0, 2].set_title('Validation Accuracy')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Accuracy')\n",
    "axes[0, 2].grid(True)\n",
    "\n",
    "# Physics violations\n",
    "axes[1, 0].plot(training_history['physics_violations'])\n",
    "axes[1, 0].set_title('Physics Constraint Violations')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Violation Magnitude')\n",
    "axes[1, 0].grid(True)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# Learning rate schedule\n",
    "lr_history = [scheduler.get_last_lr()[0] for _ in range(len(training_history['train_loss']))]\n",
    "axes[1, 1].plot(lr_history)\n",
    "axes[1, 1].set_title('Learning Rate Schedule')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].grid(True)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "# Loss ratio analysis\n",
    "physics_ratio = np.array(training_history['physics_loss']) / np.array(training_history['data_loss'])\n",
    "axes[1, 2].plot(physics_ratio)\n",
    "axes[1, 2].set_title('Physics/Data Loss Ratio')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "axes[1, 2].set_ylabel('Ratio')\n",
    "axes[1, 2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Training visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation and Physics Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate trained model\n",
    "benchmarking_suite = BenchmarkingSuite(final_config)\n",
    "\n",
    "# Test data evaluation\n",
    "test_processed = preprocessor.preprocess_dataset(test_data)\n",
    "test_loader = DataLoader(\n",
    "    test_processed,\n",
    "    batch_size=final_config.training[\"batch_size\"],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Comprehensive evaluation\n",
    "evaluation_results = benchmarking_suite.evaluate_model(\n",
    "    model, test_loader, physics_loss\n",
    ")\n",
    "\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(f\"  Test Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "print(f\"  Test Loss: {evaluation_results['total_loss']:.4f}\")\n",
    "print(f\"  Physics Consistency: {evaluation_results['physics_consistency']:.4f}\")\n",
    "print(f\"  Inference Latency: {evaluation_results['inference_latency']:.2f} ms\")\n",
    "\n",
    "# Physics validation\n",
    "physics_validation = benchmarking_suite.validate_physics_constraints(\n",
    "    model, test_loader\n",
    ")\n",
    "\n",
    "print(\"\\nPhysics Validation:\")\n",
    "for constraint, violation in physics_validation.items():\n",
    "    print(f\"  {constraint}: {violation:.6f}\")\n",
    "\n",
    "# Fault classification performance\n",
    "classification_results = benchmarking_suite.evaluate_fault_classification(\n",
    "    model, test_loader\n",
    ")\n",
    "\n",
    "print(\"\\nFault Classification Results:\")\n",
    "for fault_type, metrics in classification_results.items():\n",
    "    print(f\"  {fault_type}:\")\n",
    "    print(f\"    Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"    Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"    F1-Score: {metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Saving and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model_save_path = \"../models/av_pino_trained.pth\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "\n",
    "# Save model state\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'config': final_config,\n",
    "    'training_history': training_history,\n",
    "    'evaluation_results': evaluation_results,\n",
    "    'epoch': final_config.training['epochs']\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "\n",
    "# Save training configuration\n",
    "config_save_path = \"../models/training_config.yaml\"\n",
    "config_manager.save_config(final_config, config_save_path)\n",
    "print(f\"Configuration saved to: {config_save_path}\")\n",
    "\n",
    "# Export model for deployment\n",
    "try:\n",
    "    # Export to ONNX for edge deployment\n",
    "    dummy_input = torch.randn(1, 1, 1024)\n",
    "    onnx_path = \"../models/av_pino_model.onnx\"\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes={\n",
    "            'input': {0: 'batch_size'},\n",
    "            'output': {0: 'batch_size'}\n",
    "        }\n",
    "    )\n",
    "    print(f\"ONNX model exported to: {onnx_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"ONNX export failed: {e}\")\n",
    "\n",
    "print(\"\\nModel training and export complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Summary and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training summary\n",
    "print(\"=\" * 60)\n",
    "print(\"AV-PINO TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  Type: {final_config.model['architecture']}\")\n",
    "print(f\"  Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"  Modes: {final_config.model['modes']}\")\n",
    "print(f\"  Width: {final_config.model['width']}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {final_config.training['epochs']}\")\n",
    "print(f\"  Batch Size: {final_config.training['batch_size']}\")\n",
    "print(f\"  Learning Rate: {final_config.training['learning_rate']}\")\n",
    "print(f\"  Optimizer: {final_config.training['optimizer']}\")\n",
    "print(f\"  Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nPhysics Integration:\")\n",
    "print(f\"  Constraints: {final_config.physics['constraints']}\")\n",
    "print(f\"  Loss Weights: {final_config.physics['loss_weights']}\")\n",
    "print(f\"  Final Physics Violations: {training_history['physics_violations'][-1]:.6f}\")\n",
    "\n",
    "print(f\"\\nPerformance Results:\")\n",
    "print(f\"  Final Training Loss: {training_history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Validation Loss: {training_history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Validation Accuracy: {training_history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Test Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "print(f\"  Physics Consistency: {evaluation_results['physics_consistency']:.4f}\")\n",
    "print(f\"  Inference Latency: {evaluation_results['inference_latency']:.2f} ms\")\n",
    "\n",
    "print(f\"\\nModel Files:\")\n",
    "print(f\"  Model: {model_save_path}\")\n",
    "print(f\"  Configuration: {config_save_path}\")\n",
    "if 'onnx_path' in locals():\n",
    "    print(f\"  ONNX Export: {onnx_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training completed successfully!\")\n",
    "print(\"Ready for real-time inference and deployment.\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}